"""
Skills Fetcher - ä» skills.sh/trending è·å–æŠ€èƒ½æ’è¡Œæ¦œ
ä½¿ç”¨ Playwright å¤„ç†åŠ¨æ€æ¸²æŸ“é¡µé¢
"""
import re
import asyncio
from typing import Dict, List
from playwright.async_api import async_playwright

from src.config import SKILLS_TRENDING_URL, SKILLS_BASE_URL


class SkillsFetcher:
    """ä» skills.sh/trending è·å–æ’è¡Œæ¦œ"""

    def __init__(self, timeout: int = 30000):
        """åˆå§‹åŒ–"""
        self.base_url = SKILLS_BASE_URL
        self.trending_url = SKILLS_TRENDING_URL
        self.timeout = timeout

    def fetch(self) -> List[Dict]:
        """
        è·å– Top 100 æŠ€èƒ½åˆ—è¡¨

        Returns:
            [
                {
                    "rank": 1,
                    "name": "remotion-best-practices",
                    "owner": "remotion-dev/skills",
                    "installs": 5600,
                    "url": "https://skills.sh/remotion-dev/skills/remotion-best-practices"
                },
                ...
            ]
        """
        print(f"ğŸ“¡ æ­£åœ¨è·å–æ¦œå•: {self.trending_url}")

        # è¿è¡Œå¼‚æ­¥æ–¹æ³•
        return asyncio.run(self._fetch_async())

    async def _fetch_async(self) -> List[Dict]:
        """å¼‚æ­¥è·å–æ•°æ® - å¸¦é‡è¯•æœºåˆ¶"""
        max_retries = 3
        retry_delay = 5

        for attempt in range(max_retries):
            try:
                async with async_playwright() as p:
                    # å¯åŠ¨æµè§ˆå™¨ - CI ç¯å¢ƒä½¿ç”¨ headless æ¨¡å¼
                    browser = await p.chromium.launch(
                        headless=True,
                        args=[
                            '--disable-dev-shm-usage',
                            '--no-sandbox',
                            '--disable-setuid-sandbox',
                            '--disable-blink-features=AutomationControlled',
                        ]
                    )

                    # åˆ›å»ºé¡µé¢
                    page = await browser.new_page()

                    # è®¾ç½®ç”¨æˆ·ä»£ç†ï¼Œé¿å…è¢«è¯†åˆ«ä¸ºæœºå™¨äºº
                    await page.set_extra_http_headers({
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                    })

                    # å¯¼èˆªåˆ°é¡µé¢
                    print(f"  æ­£åœ¨åŠ è½½é¡µé¢... (å°è¯• {attempt + 1}/{max_retries})")
                    await page.goto(self.trending_url, wait_until="domcontentloaded", timeout=60000)

                    # ç­‰å¾…é¡µé¢ç¨³å®š
                    await asyncio.sleep(5)

                    # å°è¯•æ»šåŠ¨é¡µé¢ä»¥ç¡®ä¿å†…å®¹åŠ è½½
                    try:
                        await page.evaluate("window.scrollTo(0, document.body.scrollHeight / 2)")
                        await asyncio.sleep(2)
                    except:
                        pass

                    # è·å–é¡µé¢æ–‡æœ¬å†…å®¹
                    content = await page.evaluate("() => document.body.innerText")

                    # è°ƒè¯•ï¼šæ£€æŸ¥å†…å®¹
                    print(f"  é¡µé¢å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")

                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®å†…å®¹
                    if "Skills Leaderboard" not in content and "Leaderboard" not in content:
                        print(f"  âš ï¸ æœªæ‰¾åˆ°æ’è¡Œæ¦œæ ‡é¢˜ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´...")
                        await asyncio.sleep(10)
                        content = await page.evaluate("() => document.body.innerText")

                    await browser.close()

                    # è§£ææ’è¡Œæ¦œ
                    skills = self.parse_leaderboard(content)

                    if skills:
                        print(f"âœ… æˆåŠŸè·å– {len(skills)} ä¸ªæŠ€èƒ½")
                        return skills

                    raise Exception("æ— æ³•ä»é¡µé¢è§£ææŠ€èƒ½åˆ—è¡¨")

            except Exception as e:
                print(f"  âš ï¸ å°è¯• {attempt + 1} å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                else:
                    raise

        raise Exception("è·å–å¤±è´¥ï¼šå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")

    def parse_leaderboard(self, html_content: str) -> List[Dict]:
        """
        è§£ææ’è¡Œæ¦œ - skills.sh é¡µé¢ä½¿ç”¨æ–‡æœ¬æ ¼å¼

        æ ¼å¼:
        SKILLS LEADERBOARD
        ...
        1
        remotion-best-practices
        remotion-dev/skills
        7.0K
        ...
        """
        skills = []

        # æŸ¥æ‰¾æ’è¡Œæ¦œå¼€å§‹ä½ç½® - æ”¯æŒå¤šç§æ ¼å¼
        for marker in ["SKILLS LEADERBOARD", "Skills Leaderboard", "LEADERBOARD", "Leaderboard"]:
            leaderboard_start = html_content.find(marker)
            if leaderboard_start != -1:
                print(f"  æ‰¾åˆ°æ ‡è®°: '{marker}'")
                break

        if leaderboard_start == -1:
            # è°ƒè¯•ï¼šæ‰“å°é¡µé¢å†…å®¹çš„å‰1000å­—ç¬¦
            preview = html_content[:1000] if html_content else "(ç©ºå†…å®¹)"
            print(f"  âš ï¸ é¡µé¢å†…å®¹é¢„è§ˆ:\n{preview}")
            raise Exception("æœªæ‰¾åˆ° Skills Leaderboard æ ‡é¢˜")

        # æå–æ’è¡Œæ¦œéƒ¨åˆ†
        content = html_content[leaderboard_start:]

        # æ–°æ ¼å¼: æ²¡æœ‰###å‰ç¼€ï¼Œç›´æ¥æ˜¯ rank\nname\nowner\ninstalls
        # æ ¼å¼ç¤ºä¾‹:
        # 1
        # remotion-best-practices
        # remotion-dev/skills
        # 7.0K

        patterns = [
            # æ¨¡å¼1: æ–°æ ¼å¼ (æ— ###å‰ç¼€)
            r'(\d+)\s*\n\s*([a-z0-9-]+)\s*\n\s*([\w-]+/[\w-]+)\s*\n\s*([\d.]+K?)',
            # æ¨¡å¼2: å…è®¸æ›´å¤šå­—ç¬¦
            r'(\d+)\s*\n\s*([a-zA-Z0-9_-]+)\s*\n\s*([\w-]+/[\w-]+)\s*\n\s*([\d.]+K?)',
            # æ¨¡å¼3: æ—§æ ¼å¼ (æœ‰###å‰ç¼€)
            r'(\d+)\s*\n\s*###\s*([\w-]+)\s*\n\s*([\w-]+/[\w-]+)\s*\n\s*([\d.]+K?)',
            # æ¨¡å¼4: æœ€å®½æ¾
            r'(\d+)\s+([a-zA-Z0-9_-]+)\s+([\w-]+/[\w-]+)\s+([\d.]+K?)',
        ]

        skills_dict = {}  # ç”¨äºå»é‡ï¼Œä¿ç•™æœ€æ–°æ’å

        for i, pattern in enumerate(patterns):
            matches = re.finditer(pattern, content, re.MULTILINE)

            for match in matches:
                rank = int(match.group(1))
                name = match.group(2)
                owner = match.group(3)
                installs_str = match.group(4)

                # å¤„ç†å®‰è£…é‡
                installs = self._parse_installs(installs_str)

                # åªä¿ç•™æ¯ä¸ªæŠ€èƒ½çš„æœ€é«˜æ’åï¼ˆç¬¬ä¸€æ¬¡å‡ºç°ï¼‰
                if name not in skills_dict or skills_dict[name]["rank"] > rank:
                    skills_dict[name] = {
                        "rank": rank,
                        "name": name,
                        "owner": owner,
                        "installs": installs,
                        "url": f"{self.base_url}/{owner}/{name}"
                    }

            if skills_dict:
                print(f"  ä½¿ç”¨æ¨¡å¼ {i+1} åŒ¹é…åˆ° {len(skills_dict)} ä¸ªæŠ€èƒ½")
                break

        # æŒ‰æ’åæ’åº
        skills = sorted(skills_dict.values(), key=lambda x: x["rank"])

        return skills

    def _parse_installs(self, installs_str: str) -> int:
        """è§£æå®‰è£…é‡å­—ç¬¦ä¸²"""
        if not installs_str:
            return 0

        installs_str = installs_str.strip().upper()

        if "K" in installs_str:
            try:
                return int(float(installs_str.replace("K", "")) * 1000)
            except ValueError:
                return 0

        try:
            return int(installs_str)
        except ValueError:
            return 0

    def get_date_range(self) -> tuple:
        """è·å–å¯ç”¨æ—¥æœŸèŒƒå›´"""
        return None, None


def fetch_skills() -> List[Dict]:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–æŠ€èƒ½åˆ—è¡¨"""
    fetcher = SkillsFetcher()
    return fetcher.fetch()
